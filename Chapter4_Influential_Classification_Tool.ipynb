{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter4_Influential_Classification_Tool.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMX1mF6QcufdX+HhJgaYfiX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpaeX8IXyjD9",
        "colab_type": "text"
      },
      "source": [
        "# **Implementing ResNet From Scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCqMoQ7NnH4w",
        "colab_type": "text"
      },
      "source": [
        "### Data Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NOLXMPvyZjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import functools\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow.keras.regularizers as regulizers\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import (Input, Activation, Dense, Flatten, Conv2D,\n",
        "                                     MaxPooling2D,GlobalAveragePooling2D, \n",
        "                                     AveragePooling2D, BatchNormalization, add)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fHZ0DgQDiZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F0I-101yuRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_builder = tfds.builder('cifar100')\n",
        "cifar_builder.download_and_prepare()\n",
        "\n",
        "print(f'{cifar_builder.info}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpBCw9ZXzNx8",
        "colab_type": "code",
        "outputId": "dd53749d-c302-47f7-e303-c8b296468c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "print(cifar_builder.info.features['label'].names)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFvSWt9Tz3l9",
        "colab_type": "code",
        "outputId": "23281a5e-7bc9-4342-da95-0940899aedc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "input_shape = [224, 224, 3]\n",
        "batch_size = 32\n",
        "num_epochs = 300\n",
        "\n",
        "train_cifar_dataset = cifar_builder.as_dataset(split=tfds.Split.TRAIN)\n",
        "val_cifar_dataset = cifar_builder.as_dataset(split=tfds.Split.TEST)\n",
        "\n",
        "num_classes = cifar_builder.info.features['label'].num_classes\n",
        "\n",
        "num_train_images = cifar_builder.info.splits['train'].num_examples\n",
        "num_valid_images = cifar_builder.info.splits['test'].num_examples"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klw-Jepd1W7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cifar_dataset = train_cifar_dataset.repeat(num_epochs).shuffle(10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dCvAbyW2Gn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _prepare_data_fn(features, input_shape, augment=False):\n",
        "    \"\"\"\n",
        "    Resize image to expected dimensions, and opt. apply some random transformations.\n",
        "    :param features:    Data\n",
        "    :param input_shape: Shape expected by the models (images will be resized accordingly)\n",
        "    :param augment:     Flag to apply some random augmentations to the images\n",
        "    :return:            Augmented Images, Labels\n",
        "    \"\"\"\n",
        "    input_shape = tf.convert_to_tensor(input_shape)\n",
        "    \n",
        "    # Tensorflow-Dataset returns batches as feature dictionaries, expected by Estimators.\n",
        "    # To train Keras models, it is more straightforward to return the batch content as tuples:\n",
        "    image = features['image']\n",
        "    label = features['label']\n",
        "    # Convert the images to float type, also scaling their values from [0, 255] to [0., 1.]:\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    \n",
        "    if augment:\n",
        "        # Randomly applied horizontal flip:\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "        # Random B/S changes:\n",
        "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "        image = tf.clip_by_value(image, 0.0, 1.0) # keeping pixel values in check\n",
        "\n",
        "        # Random resize and random crop back to expected size:\n",
        "        \n",
        "        random_scale_factor = tf.random.uniform([1], minval=1., maxval=1.4, dtype=tf.float32)\n",
        "        scaled_height = tf.cast(tf.cast(input_shape[0], tf.float32) * random_scale_factor, \n",
        "                                tf.int32)\n",
        "        scaled_width = tf.cast(tf.cast(input_shape[1], tf.float32) * random_scale_factor, \n",
        "                               tf.int32)\n",
        "        scaled_shape = tf.squeeze(tf.stack([scaled_height, scaled_width]))\n",
        "        image = tf.image.resize(image, scaled_shape)\n",
        "        image = tf.image.random_crop(image, input_shape)\n",
        "    else:\n",
        "        image = tf.image.resize(image, input_shape[:2])\n",
        "        \n",
        "    return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_EcmDLe7Ayk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prepare_data_fn_for_train = functools.partial(_prepare_data_fn, \n",
        "                                              input_shape=input_shape,\n",
        "                                              augment=True)\n",
        "\n",
        "train_cifar_dataset = train_cifar_dataset.map(prepare_data_fn_for_train)\n",
        "\n",
        "# We also ask the dataset to batch the samples:\n",
        "train_cifar_dataset = train_cifar_dataset.batch(batch_size)\n",
        "\n",
        "train_cifar_dataset = train_cifar_dataset.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XheGO5hgCH2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prepare_data_fn_for_val = functools.partial(_prepare_data_fn,\n",
        "                                            input_shape=input_shape)\n",
        "\n",
        "val_cifar_dataset = (val_cifar_dataset\n",
        "                    .repeat()\n",
        "                    .map(prepare_data_fn_for_val, num_parallel_calls=4)\n",
        "                    .batch(batch_size)\n",
        "                    .prefetch(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e8tahGgD5qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_steps_per_epoch = math.ceil(num_train_images/batch_size)\n",
        "val_steps_per_epoch = math.ceil(num_valid_images/batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQwlQR8mnNIk",
        "colab_type": "text"
      },
      "source": [
        "### ResNet Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRp6i8gyFAee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _res_conv(filters, \n",
        "              kernel_size=3, \n",
        "              padding='same', \n",
        "              strides=1, \n",
        "              use_relu=True, \n",
        "              use_bias=False, \n",
        "              name='cbr', \n",
        "              kernel_initializer='he_normal', \n",
        "              kernel_regularizer=regulizers.l2(1e-4)):\n",
        "    \"\"\"\n",
        "    Return a layer block chaining conv, batchnrom and reLU activation.\n",
        "    :param filters:                 Number of filters.\n",
        "    :param kernel_size:             Kernel size.\n",
        "    :param padding:                 Convolution padding.\n",
        "    :param strides:                 Convolution strides.\n",
        "    :param use_relu:                Flag to apply ReLu activation at the end.\n",
        "    :param use_bias:                Flag to use bias or not in Conv layer.\n",
        "    :param name:                    Name suffix for the layers.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :return:                        Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x):\n",
        "\n",
        "        conv = Conv2D(filters=filters, \n",
        "                      kernel_size=kernel_size, \n",
        "                      padding=padding,\n",
        "                      strides=strides, \n",
        "                      use_bias=use_bias, \n",
        "                      kernel_initializer=kernel_initializer, \n",
        "                      kernel_regularizer=kernel_regularizer, \n",
        "                      name=f'{name}_c')(x)\n",
        "\n",
        "        res = BatchNormalization(axis=-1, name=f'{name}_bn')(conv)\n",
        "\n",
        "        if use_relu:\n",
        "            res = Activation(\"relu\", name=f'{name}_r')(res)\n",
        "        return res\n",
        "\n",
        "    return layer_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MmTKJnru8yE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _merge_with_shortcut(kernel_initializer='he_normal', \n",
        "                         kernel_regularizer=regulizers.l2(1e-4), \n",
        "                         name='block'):\n",
        "    \"\"\"\n",
        "    Return a layer block which merge an input tensor and the corresponding \n",
        "    residual output tensor from another branch.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :param name:                    Name suffix for the layers.\n",
        "    :return:                        Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x, x_residual):\n",
        "        # We check if `x_residual` was scaled down. \n",
        "        # If so, we scale `x` accordingly with a 1x1 conv:\n",
        "        x_shape = tf.keras.backend.int_shape(x)\n",
        "        x_residual_shape = tf.keras.backend.int_shape(x_residual)\n",
        "        if x_shape == x_residual_shape:\n",
        "            shortcut = x\n",
        "        else:\n",
        "            strides = (\n",
        "                # Vertical Strides\n",
        "                int(round(x_shape[1] / x_residual_shape[1])),\n",
        "                # Horizontal strides\n",
        "                int(round(x_shape[2] / x_residual_shape[2]))\n",
        "            )\n",
        "            x_residual_channels = x_residual_shape[3]\n",
        "            shortcut = Conv2D(filters=x_residual_channels, \n",
        "                              kernel_size=(1, 1), \n",
        "                              padding=\"valid\", \n",
        "                              strides=strides,\n",
        "                              kernel_initializer=kernel_initializer, \n",
        "                              kernel_regularizer=kernel_regularizer,\n",
        "                              name=name + '_shortcut_c')(x)\n",
        "\n",
        "        merge = add([shortcut, x_residual])\n",
        "        return merge\n",
        "\n",
        "    return layer_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2SiEwnkwere",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _residual_block_basic(filters, \n",
        "                          kernel_size=3, \n",
        "                          strides=1, \n",
        "                          use_bias=False, \n",
        "                          name='res_basic',\n",
        "                          kernel_initializer='he_normal', \n",
        "                          kernel_regularizer=regulizers.l2(1e-4)):\n",
        "    \"\"\"\n",
        "    Return a basic residual layer block.\n",
        "    :param filters:                 Number of filters.\n",
        "    :param kernel_size:             Kernel size.\n",
        "    :param strides:                 Convolution strides\n",
        "    :param use_bias:                Flag to use bias or not in Conv layer.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :return:                        Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x):\n",
        "        x_conv1 = _res_conv(filters=filters, \n",
        "                            kernel_size=kernel_size, \n",
        "                            padding='same', \n",
        "                            strides=strides, \n",
        "                            use_relu=True, use_bias=use_bias,\n",
        "                            kernel_initializer=kernel_initializer, \n",
        "                            kernel_regularizer=kernel_regularizer,\n",
        "                            name=name + '_cbr_1')(x)\n",
        "        x_residual = _res_conv(filters=filters, \n",
        "                               kernel_size=kernel_size, \n",
        "                               padding='same', \n",
        "                               strides=1, \n",
        "                               use_relu=False, \n",
        "                               use_bias=use_bias,\n",
        "                               kernel_initializer=kernel_initializer, \n",
        "                               kernel_regularizer=kernel_regularizer,\n",
        "                               name=name + '_cbr_2')(x_conv1)\n",
        "        merge = _merge_with_shortcut(kernel_initializer, \n",
        "                                     kernel_regularizer,\n",
        "                                     name=name)(x, x_residual)\n",
        "        merge = Activation('relu')(merge)\n",
        "        return merge\n",
        "\n",
        "    return layer_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwBMbpyKx9Km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _residual_block_bottleneck(filters, \n",
        "                               kernel_size=3, \n",
        "                               strides=1, \n",
        "                               use_bias=False, \n",
        "                               name='res_bottleneck',\n",
        "                               kernel_initializer='he_normal', \n",
        "                               kernel_regularizer=regulizers.l2(1e-4)):\n",
        "    \"\"\"\n",
        "    Return a residual layer block with bottleneck, \n",
        "    recommended for deep ResNets (depth > 34).\n",
        "    \n",
        "    :param filters:                 Number of filters.\n",
        "    :param kernel_size:             Kernel size.\n",
        "    :param strides:                 Convolution strides\n",
        "    :param use_bias:                Flag to use bias or not in Conv layer.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :return:                        Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x):\n",
        "        x_bottleneck = _res_conv(filters=filters, \n",
        "                                 kernel_size=1, \n",
        "                                 padding='valid', \n",
        "                                 strides=strides, \n",
        "                                 use_relu=True, \n",
        "                                 use_bias=use_bias,\n",
        "                                 kernel_initializer=kernel_initializer, \n",
        "                                 kernel_regularizer=kernel_regularizer,\n",
        "                                 name=name + '_cbr1')(x)\n",
        "        x_conv = _res_conv(filters=filters, \n",
        "                           kernel_size=kernel_size, \n",
        "                           padding='same', \n",
        "                           strides=1, \n",
        "                           use_relu=True, \n",
        "                           use_bias=use_bias,\n",
        "                           kernel_initializer=kernel_initializer, \n",
        "                           kernel_regularizer=kernel_regularizer,\n",
        "                           name=name + '_cbr2')(x_bottleneck)\n",
        "        x_residual = _res_conv(filters=filters * 4, \n",
        "                               kernel_size=1, \n",
        "                               padding='valid', \n",
        "                               strides=1, \n",
        "                               use_relu=False, \n",
        "                               use_bias=use_bias,\n",
        "                               kernel_initializer=kernel_initializer, \n",
        "                               kernel_regularizer=kernel_regularizer,\n",
        "                               name=name + '_cbr3')(x_conv)\n",
        "        merge = _merge_with_shortcut(kernel_initializer, \n",
        "                                     kernel_regularizer, \n",
        "                                     name=name)(x, x_residual)\n",
        "        merge = Activation('relu')(merge)\n",
        "        return merge\n",
        "\n",
        "    return layer_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3c9wsk_zcNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _residual_macroblock(block_fn, filters, repetitions=3, kernel_size=3, \n",
        "                         strides_1st_block=1, use_bias=False,\n",
        "                         kernel_initializer='he_normal', \n",
        "                         kernel_regularizer=regulizers.l2(1e-4),\n",
        "                         name='res_macroblock'):\n",
        "    \"\"\"\n",
        "    Return a layer block, composed of a repetition of `N` residual blocks.\n",
        "    :param block_fn:               Block layer method to be used.\n",
        "    :param repetitions:            Number of times the block should be repeated.\n",
        "    :param filters:                Number of filters.\n",
        "    :param kernel_size:            Kernel size.\n",
        "    :param strides_1st_block:      Convolution strides for the 1st block.\n",
        "    :param use_bias:               Flag to use bias or not in Conv layer.\n",
        "    :param kernel_initializer:     Kernel initialisation method name.\n",
        "    :param kernel_regularizer:     Kernel regularizer.\n",
        "    :return:                       Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x):\n",
        "        for i in range(repetitions):\n",
        "            block_name = f\"{name}_{i}\" \n",
        "            strides = strides_1st_block if i == 0 else 1\n",
        "            x = block_fn(filters=filters, kernel_size=kernel_size, \n",
        "                         strides=strides, use_bias=use_bias,\n",
        "                         kernel_initializer=kernel_initializer, \n",
        "                         kernel_regularizer=kernel_regularizer,\n",
        "                         name=block_name)(x)\n",
        "        return x\n",
        "\n",
        "    return layer_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quOjpAShzujn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _residual_macroblock(block_fn, filters, repetitions=3, kernel_size=3, \n",
        "                         strides_1st_block=1, use_bias=False,\n",
        "                         kernel_initializer='he_normal', \n",
        "                         kernel_regularizer=regulizers.l2(1e-4),\n",
        "                         name='res_macroblock'):\n",
        "    \"\"\"\n",
        "    Return a layer block, composed of a repetition of `N` residual blocks.\n",
        "    :param block_fn:               Block layer method to be used.\n",
        "    :param repetitions:            Number of times the block should be repeated.\n",
        "    :param filters:                Number of filters.\n",
        "    :param kernel_size:            Kernel size.\n",
        "    :param strides_1st_block:      Convolution strides for the 1st block.\n",
        "    :param use_bias:               Flag to use bias or not in Conv layer.\n",
        "    :param kernel_initializer:     Kernel initialisation method name.\n",
        "    :param kernel_regularizer:     Kernel regularizer.\n",
        "    :return:                       Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x):\n",
        "        for i in range(repetitions):\n",
        "            block_name = f\"{name}_{i}\" \n",
        "            strides = strides_1st_block if i == 0 else 1\n",
        "            x = block_fn(filters=filters, kernel_size=kernel_size, \n",
        "                         strides=strides, use_bias=use_bias,\n",
        "                         kernel_initializer=kernel_initializer, \n",
        "                         kernel_regularizer=kernel_regularizer,\n",
        "                         name=block_name)(x)\n",
        "        return x\n",
        "\n",
        "    return layer_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCwHRuZh1JYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet(input_shape, num_classes=1000, block_fn=_residual_block_basic, \n",
        "           repetitions=(2, 2, 2, 2), use_bias=False, \n",
        "           kernel_initializer='he_normal', \n",
        "           kernel_regularizer=regulizers.l2(1e-4)):\n",
        "    \"\"\"\n",
        "    Build a ResNet model for classification.\n",
        "    :param input_shape:             Input shape (e.g. (224, 224, 3))\n",
        "    :param num_classes:             Number of classes to predict\n",
        "    :param block_fn:                Block layer method to be used.\n",
        "    :param repetitions:             List of repetitions for each macro-blocks \n",
        "                                    the network should contain.\n",
        "    :param use_bias:                Flag to use bias or not in Conv layer.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :return:                        ResNet model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Input and 1st layers:\n",
        "    inputs = Input(shape=input_shape)\n",
        "    conv = _res_conv(filters=64, kernel_size=7, strides=2, use_relu=True, \n",
        "                     use_bias=use_bias,kernel_initializer=kernel_initializer, \n",
        "                     kernel_regularizer=kernel_regularizer)(inputs)\n",
        "    maxpool = MaxPooling2D(pool_size=3, strides=2, padding='same')(conv)\n",
        "\n",
        "    # Chain of residual blocks:\n",
        "    filters = 64\n",
        "    strides = 2\n",
        "    res_block = maxpool\n",
        "    for i, repet in enumerate(repetitions):\n",
        "        # We do not further reduce the input size for the 1st block\n",
        "        # (max-pool applied just before):\n",
        "        block_strides = strides if i != 0 else 1\n",
        "        macroblock_name = \"block_{}\".format(i) \n",
        "        res_block = _residual_macroblock(\n",
        "            block_fn=block_fn, repetitions=repet, \n",
        "            name=macroblock_name,filters=filters, \n",
        "            strides_1st_block=block_strides, \n",
        "            use_bias=use_bias, kernel_initializer=kernel_initializer, \n",
        "            kernel_regularizer=kernel_regularizer)(res_block)\n",
        "        filters = min(filters * 2, 1024) # we limit to 1024 filters max\n",
        "\n",
        "    # Final layers for prediction:\n",
        "    res_spatial_dim = tf.keras.backend.int_shape(res_block)[1:3]\n",
        "    avg_pool = AveragePooling2D(pool_size=res_spatial_dim, strides=1)(res_block)\n",
        "    flatten = Flatten()(avg_pool)\n",
        "    predictions = Dense(units=num_classes, \n",
        "                        \n",
        "                        kernel_initializer=kernel_initializer, \n",
        "                        activation='softmax')(flatten)\n",
        "\n",
        "    # Model:\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR1njchh2Mia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet18(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_basic, \n",
        "                  repetitions=(2, 2, 2, 2), use_bias=use_bias, \n",
        "                  kernel_initializer=kernel_initializer, \n",
        "                  kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "\n",
        "def ResNet34(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_basic, \n",
        "                  repetitions=(3, 4, 6, 3), use_bias=use_bias, \n",
        "                  kernel_initializer=kernel_initializer, \n",
        "                  kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "\n",
        "def ResNet50(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    # Note: ResNet50 is similar to ResNet34,\n",
        "    # with the basic blocks replaced by bottleneck ones.\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_bottleneck,\n",
        "                  repetitions=(3, 4, 6, 3), use_bias=use_bias, \n",
        "                  kernel_initializer=kernel_initializer, \n",
        "                  kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "\n",
        "def ResNet101(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_bottleneck,\n",
        "                  repetitions=(3, 4, 23, 3), use_bias=use_bias, \n",
        "                  kernel_initializer=kernel_initializer, \n",
        "                  kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "\n",
        "def ResNet152(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_bottleneck,\n",
        "                  repetitions=(3, 8, 36, 3), use_bias=use_bias, \n",
        "                  kernel_initializer=kernel_initializer, \n",
        "                  kernel_regularizer=kernel_regularizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUXIL-n4i3B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f4b7b8d-dcda-4092-f2fc-e3d02b5bdfeb"
      },
      "source": [
        "resnet50 = ResNet50(input_shape=input_shape, num_classes=num_classes)\n",
        "resnet50.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "cbr_c (Conv2D)                  (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cbr_bn (BatchNormalization)     (None, 112, 112, 64) 256         cbr_c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "cbr_r (Activation)              (None, 112, 112, 64) 0           cbr_bn[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           cbr_r[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_0_0_cbr1_c (Conv2D)       (None, 56, 56, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_0_0_cbr1_bn (BatchNormali (None, 56, 56, 64)   256         block_0_0_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_0_cbr1_r (Activation)   (None, 56, 56, 64)   0           block_0_0_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_0_0_cbr2_c (Conv2D)       (None, 56, 56, 64)   36928       block_0_0_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_0_cbr2_bn (BatchNormali (None, 56, 56, 64)   256         block_0_0_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_0_cbr2_r (Activation)   (None, 56, 56, 64)   0           block_0_0_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_0_0_cbr3_c (Conv2D)       (None, 56, 56, 256)  16640       block_0_0_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_0_shortcut_c (Conv2D)   (None, 56, 56, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_0_0_cbr3_bn (BatchNormali (None, 56, 56, 256)  1024        block_0_0_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 56, 56, 256)  0           block_0_0_shortcut_c[0][0]       \n",
            "                                                                 block_0_0_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 56, 56, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block_0_1_cbr1_c (Conv2D)       (None, 56, 56, 64)   16448       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block_0_1_cbr1_bn (BatchNormali (None, 56, 56, 64)   256         block_0_1_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_1_cbr1_r (Activation)   (None, 56, 56, 64)   0           block_0_1_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_0_1_cbr2_c (Conv2D)       (None, 56, 56, 64)   36928       block_0_1_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_1_cbr2_bn (BatchNormali (None, 56, 56, 64)   256         block_0_1_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_1_cbr2_r (Activation)   (None, 56, 56, 64)   0           block_0_1_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_0_1_cbr3_c (Conv2D)       (None, 56, 56, 256)  16640       block_0_1_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_1_cbr3_bn (BatchNormali (None, 56, 56, 256)  1024        block_0_1_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           activation[0][0]                 \n",
            "                                                                 block_0_1_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_0_2_cbr1_c (Conv2D)       (None, 56, 56, 64)   16448       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_0_2_cbr1_bn (BatchNormali (None, 56, 56, 64)   256         block_0_2_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_2_cbr1_r (Activation)   (None, 56, 56, 64)   0           block_0_2_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_0_2_cbr2_c (Conv2D)       (None, 56, 56, 64)   36928       block_0_2_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_2_cbr2_bn (BatchNormali (None, 56, 56, 64)   256         block_0_2_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_2_cbr2_r (Activation)   (None, 56, 56, 64)   0           block_0_2_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_0_2_cbr3_c (Conv2D)       (None, 56, 56, 256)  16640       block_0_2_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_0_2_cbr3_bn (BatchNormali (None, 56, 56, 256)  1024        block_0_2_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           activation_1[0][0]               \n",
            "                                                                 block_0_2_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_0_cbr1_c (Conv2D)       (None, 28, 28, 128)  32896       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_1_0_cbr1_bn (BatchNormali (None, 28, 28, 128)  512         block_1_0_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_0_cbr1_r (Activation)   (None, 28, 28, 128)  0           block_1_0_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_0_cbr2_c (Conv2D)       (None, 28, 28, 128)  147584      block_1_0_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_0_cbr2_bn (BatchNormali (None, 28, 28, 128)  512         block_1_0_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_0_cbr2_r (Activation)   (None, 28, 28, 128)  0           block_1_0_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_0_cbr3_c (Conv2D)       (None, 28, 28, 512)  66048       block_1_0_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_0_shortcut_c (Conv2D)   (None, 28, 28, 512)  131584      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_1_0_cbr3_bn (BatchNormali (None, 28, 28, 512)  2048        block_1_0_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 512)  0           block_1_0_shortcut_c[0][0]       \n",
            "                                                                 block_1_0_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 28, 28, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_1_cbr1_c (Conv2D)       (None, 28, 28, 128)  65664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_1_1_cbr1_bn (BatchNormali (None, 28, 28, 128)  512         block_1_1_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_1_cbr1_r (Activation)   (None, 28, 28, 128)  0           block_1_1_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_1_cbr2_c (Conv2D)       (None, 28, 28, 128)  147584      block_1_1_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_1_cbr2_bn (BatchNormali (None, 28, 28, 128)  512         block_1_1_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_1_cbr2_r (Activation)   (None, 28, 28, 128)  0           block_1_1_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_1_cbr3_c (Conv2D)       (None, 28, 28, 512)  66048       block_1_1_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_1_cbr3_bn (BatchNormali (None, 28, 28, 512)  2048        block_1_1_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           activation_3[0][0]               \n",
            "                                                                 block_1_1_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_2_cbr1_c (Conv2D)       (None, 28, 28, 128)  65664       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_1_2_cbr1_bn (BatchNormali (None, 28, 28, 128)  512         block_1_2_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_2_cbr1_r (Activation)   (None, 28, 28, 128)  0           block_1_2_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_2_cbr2_c (Conv2D)       (None, 28, 28, 128)  147584      block_1_2_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_2_cbr2_bn (BatchNormali (None, 28, 28, 128)  512         block_1_2_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_2_cbr2_r (Activation)   (None, 28, 28, 128)  0           block_1_2_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_2_cbr3_c (Conv2D)       (None, 28, 28, 512)  66048       block_1_2_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_2_cbr3_bn (BatchNormali (None, 28, 28, 512)  2048        block_1_2_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           activation_4[0][0]               \n",
            "                                                                 block_1_2_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_3_cbr1_c (Conv2D)       (None, 28, 28, 128)  65664       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_1_3_cbr1_bn (BatchNormali (None, 28, 28, 128)  512         block_1_3_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_3_cbr1_r (Activation)   (None, 28, 28, 128)  0           block_1_3_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_3_cbr2_c (Conv2D)       (None, 28, 28, 128)  147584      block_1_3_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_3_cbr2_bn (BatchNormali (None, 28, 28, 128)  512         block_1_3_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_3_cbr2_r (Activation)   (None, 28, 28, 128)  0           block_1_3_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_3_cbr3_c (Conv2D)       (None, 28, 28, 512)  66048       block_1_3_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_1_3_cbr3_bn (BatchNormali (None, 28, 28, 512)  2048        block_1_3_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           activation_5[0][0]               \n",
            "                                                                 block_1_3_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_2_0_cbr1_c (Conv2D)       (None, 14, 14, 256)  131328      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_2_0_cbr1_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_0_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_0_cbr1_r (Activation)   (None, 14, 14, 256)  0           block_2_0_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_0_cbr2_c (Conv2D)       (None, 14, 14, 256)  590080      block_2_0_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_0_cbr2_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_0_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_0_cbr2_r (Activation)   (None, 14, 14, 256)  0           block_2_0_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_0_cbr3_c (Conv2D)       (None, 14, 14, 1024) 263168      block_2_0_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_0_shortcut_c (Conv2D)   (None, 14, 14, 1024) 525312      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_2_0_cbr3_bn (BatchNormali (None, 14, 14, 1024) 4096        block_2_0_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 1024) 0           block_2_0_shortcut_c[0][0]       \n",
            "                                                                 block_2_0_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_2_1_cbr1_c (Conv2D)       (None, 14, 14, 256)  262400      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_2_1_cbr1_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_1_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_1_cbr1_r (Activation)   (None, 14, 14, 256)  0           block_2_1_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_1_cbr2_c (Conv2D)       (None, 14, 14, 256)  590080      block_2_1_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_1_cbr2_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_1_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_1_cbr2_r (Activation)   (None, 14, 14, 256)  0           block_2_1_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_1_cbr3_c (Conv2D)       (None, 14, 14, 1024) 263168      block_2_1_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_1_cbr3_bn (BatchNormali (None, 14, 14, 1024) 4096        block_2_1_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           activation_7[0][0]               \n",
            "                                                                 block_2_1_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_2_2_cbr1_c (Conv2D)       (None, 14, 14, 256)  262400      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_2_2_cbr1_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_2_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_2_cbr1_r (Activation)   (None, 14, 14, 256)  0           block_2_2_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_2_cbr2_c (Conv2D)       (None, 14, 14, 256)  590080      block_2_2_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_2_cbr2_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_2_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_2_cbr2_r (Activation)   (None, 14, 14, 256)  0           block_2_2_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_2_cbr3_c (Conv2D)       (None, 14, 14, 1024) 263168      block_2_2_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_2_cbr3_bn (BatchNormali (None, 14, 14, 1024) 4096        block_2_2_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           activation_8[0][0]               \n",
            "                                                                 block_2_2_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_2_3_cbr1_c (Conv2D)       (None, 14, 14, 256)  262400      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_2_3_cbr1_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_3_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_3_cbr1_r (Activation)   (None, 14, 14, 256)  0           block_2_3_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_3_cbr2_c (Conv2D)       (None, 14, 14, 256)  590080      block_2_3_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_3_cbr2_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_3_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_3_cbr2_r (Activation)   (None, 14, 14, 256)  0           block_2_3_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_3_cbr3_c (Conv2D)       (None, 14, 14, 1024) 263168      block_2_3_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_3_cbr3_bn (BatchNormali (None, 14, 14, 1024) 4096        block_2_3_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           activation_9[0][0]               \n",
            "                                                                 block_2_3_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_4_cbr1_c (Conv2D)       (None, 14, 14, 256)  262400      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_2_4_cbr1_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_4_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_4_cbr1_r (Activation)   (None, 14, 14, 256)  0           block_2_4_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_4_cbr2_c (Conv2D)       (None, 14, 14, 256)  590080      block_2_4_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_4_cbr2_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_4_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_4_cbr2_r (Activation)   (None, 14, 14, 256)  0           block_2_4_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_4_cbr3_c (Conv2D)       (None, 14, 14, 1024) 263168      block_2_4_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_4_cbr3_bn (BatchNormali (None, 14, 14, 1024) 4096        block_2_4_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           activation_10[0][0]              \n",
            "                                                                 block_2_4_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_5_cbr1_c (Conv2D)       (None, 14, 14, 256)  262400      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_2_5_cbr1_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_5_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_5_cbr1_r (Activation)   (None, 14, 14, 256)  0           block_2_5_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_5_cbr2_c (Conv2D)       (None, 14, 14, 256)  590080      block_2_5_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_5_cbr2_bn (BatchNormali (None, 14, 14, 256)  1024        block_2_5_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_5_cbr2_r (Activation)   (None, 14, 14, 256)  0           block_2_5_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_5_cbr3_c (Conv2D)       (None, 14, 14, 1024) 263168      block_2_5_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_5_cbr3_bn (BatchNormali (None, 14, 14, 1024) 4096        block_2_5_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           activation_11[0][0]              \n",
            "                                                                 block_2_5_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_0_cbr1_c (Conv2D)       (None, 7, 7, 512)    524800      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_3_0_cbr1_bn (BatchNormali (None, 7, 7, 512)    2048        block_3_0_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_0_cbr1_r (Activation)   (None, 7, 7, 512)    0           block_3_0_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_0_cbr2_c (Conv2D)       (None, 7, 7, 512)    2359808     block_3_0_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_0_cbr2_bn (BatchNormali (None, 7, 7, 512)    2048        block_3_0_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_0_cbr2_r (Activation)   (None, 7, 7, 512)    0           block_3_0_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_0_cbr3_c (Conv2D)       (None, 7, 7, 2048)   1050624     block_3_0_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_0_shortcut_c (Conv2D)   (None, 7, 7, 2048)   2099200     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_3_0_cbr3_bn (BatchNormali (None, 7, 7, 2048)   8192        block_3_0_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 7, 7, 2048)   0           block_3_0_shortcut_c[0][0]       \n",
            "                                                                 block_3_0_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_1_cbr1_c (Conv2D)       (None, 7, 7, 512)    1049088     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_3_1_cbr1_bn (BatchNormali (None, 7, 7, 512)    2048        block_3_1_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_1_cbr1_r (Activation)   (None, 7, 7, 512)    0           block_3_1_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_1_cbr2_c (Conv2D)       (None, 7, 7, 512)    2359808     block_3_1_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_1_cbr2_bn (BatchNormali (None, 7, 7, 512)    2048        block_3_1_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_1_cbr2_r (Activation)   (None, 7, 7, 512)    0           block_3_1_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_1_cbr3_c (Conv2D)       (None, 7, 7, 2048)   1050624     block_3_1_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_1_cbr3_bn (BatchNormali (None, 7, 7, 2048)   8192        block_3_1_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           activation_13[0][0]              \n",
            "                                                                 block_3_1_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_2_cbr1_c (Conv2D)       (None, 7, 7, 512)    1049088     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_3_2_cbr1_bn (BatchNormali (None, 7, 7, 512)    2048        block_3_2_cbr1_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_2_cbr1_r (Activation)   (None, 7, 7, 512)    0           block_3_2_cbr1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_2_cbr2_c (Conv2D)       (None, 7, 7, 512)    2359808     block_3_2_cbr1_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_2_cbr2_bn (BatchNormali (None, 7, 7, 512)    2048        block_3_2_cbr2_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_2_cbr2_r (Activation)   (None, 7, 7, 512)    0           block_3_2_cbr2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_2_cbr3_c (Conv2D)       (None, 7, 7, 2048)   1050624     block_3_2_cbr2_r[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_2_cbr3_bn (BatchNormali (None, 7, 7, 2048)   8192        block_3_2_cbr3_c[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           activation_14[0][0]              \n",
            "                                                                 block_3_2_cbr3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          204900      flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,777,252\n",
            "Trainable params: 23,731,812\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AJON-s94nWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "accuracy_metric = tf.metrics.SparseCategoricalAccuracy(name='acc')\n",
        "top5_accuracy_metric = tf.metrics.SparseTopKCategoricalAccuracy(\n",
        "    k=5, name='top5_acc'\n",
        ")\n",
        "resnet50.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', \n",
        "                 metrics=[accuracy_metric, top5_accuracy_metric])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGkc2dvb5dQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting some variables to format the logs:\n",
        "log_begin_red, log_begin_blue, log_begin_green = '\\033[91m','\\033[94m','\\033[92m'\n",
        "log_begin_bold, log_begin_underline = '\\033[1m', '\\033[4m'\n",
        "log_end_format = '\\033[0m'\n",
        "\n",
        "class SimpleLogCallback(tf.keras.callbacks.Callback):\n",
        "    \"\"\" Keras callback for simple, denser console logs.\"\"\"\n",
        "\n",
        "    def __init__(self, metrics_dict, num_epochs='?', log_frequency=1,\n",
        "                 metric_string_template=\n",
        "                 '\\033[1m[[name]]\\033[0m = \\033[94m{[[value]]:5.3f}\\033[0m'):\n",
        "        \"\"\"\n",
        "        Initialize the Callback.\n",
        "        :param metrics_dict:            Dictionary containing mappings for \n",
        "                                        metrics names/keys e.g. {\"accuracy\": \n",
        "                                        \"acc\", \"val. accuracy\": \"val_acc\"}\n",
        "        :param num_epochs:              Number of training epochs\n",
        "        :param log_frequency:           Log frequency (in epochs)\n",
        "        :param metric_string_template:  (opt.) String template to print each \n",
        "                                        metric\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.metrics_dict = collections.OrderedDict(metrics_dict)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.log_frequency = log_frequency\n",
        "\n",
        "        # We build a format string to later print the metrics, \n",
        "        # (e.g. \"Epoch 0/9: loss = 1.00; val-loss = 2.00\")\n",
        "        log_string_template = 'Epoch {0:2}/{1}: '\n",
        "        separator = '; '\n",
        "\n",
        "        i = 2\n",
        "        for metric_name in self.metrics_dict:\n",
        "            templ = metric_string_template.replace(\n",
        "                '[[name]]', metric_name).replace(\n",
        "                    '[[value]]', str(i))\n",
        "            log_string_template += templ + separator\n",
        "            i += 1\n",
        "\n",
        "        # We remove the \"; \" after the last element:\n",
        "        log_string_template = log_string_template[:-len(separator)]\n",
        "        self.log_string_template = log_string_template\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        print(f\"Training: {log_begin_red}start{log_end_format}\")\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        print(f\"Training: {log_begin_green}end{log_end_format}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (epoch - 1) % self.log_frequency == 0 or epoch == self.num_epochs:\n",
        "            values = [logs[self.metrics_dict[metric_name]] \n",
        "                      for metric_name in self.metrics_dict]\n",
        "            print(self.log_string_template.format(epoch, self.num_epochs, \n",
        "                                                  *values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9Y6TtJN64QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics_to_print = collections.OrderedDict([(\"loss\", \"loss\"), \n",
        "                                            (\"v-loss\", \"val_loss\"),\n",
        "                                            (\"acc\", \"acc\"), \n",
        "                                            (\"v-acc\", \"val_acc\"),\n",
        "                                            (\"top5-acc\", \"top5_acc\"), \n",
        "                                            (\"v-top5-acc\", \"val_top5_acc\")])\n",
        "\n",
        "callback_simple_log = SimpleLogCallback(metrics_to_print, \n",
        "                                        num_epochs=num_epochs, log_frequency=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00PmNqWt7zKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = './models/resnet_from_scratch'\n",
        "callbacks = [\n",
        "    # Callback to interrupt the training if the validation loss/metrics \n",
        "    # stops improving for some epochs:\n",
        "    tf.keras.callbacks.EarlyStopping(patience=8, monitor='val_acc',\n",
        "                                     restore_best_weights=True),\n",
        "    # Callback to log the graph, losses and metrics into TensorBoard:\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=model_dir, histogram_freq=0, \n",
        "                                   write_graph=True),\n",
        "    # Callback to save the model (e.g., every 5 epochs), specifying the epoch \n",
        "    # and val-loss in the filename:\n",
        "    tf.keras.callbacks.ModelCheckpoint(os.path.join(model_dir, \n",
        "                     'weights-epoch{epoch:02d}-loss{val_loss:.2f}.h5'), \n",
        "                     save_freq=5),\n",
        "    # Log callback:\n",
        "    callback_simple_log \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-57a59fo8JcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = resnet50.fit(train_cifar_dataset,  \n",
        "                       epochs=num_epochs, steps_per_epoch=train_steps_per_epoch,\n",
        "                       validation_data=(val_cifar_dataset), \n",
        "                       validation_steps=val_steps_per_epoch,\n",
        "                       verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97aU_rWf8rut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(3, 2, figsize=(15, 10), sharex='col')\n",
        "ax[0, 0].set_title(\"loss\")\n",
        "ax[0, 1].set_title(\"val-loss\")\n",
        "ax[1, 0].set_title(\"acc\")\n",
        "ax[1, 1].set_title(\"val-acc\")\n",
        "ax[2, 0].set_title(\"top5-acc\")\n",
        "ax[2, 1].set_title(\"val-top5-acc\")\n",
        "\n",
        "ax[0, 0].plot(history.history['loss'])\n",
        "ax[0, 1].plot(history.history['val_loss'])\n",
        "ax[1, 0].plot(history.history['acc'])\n",
        "ax[1, 1].plot(history.history['val_acc'])\n",
        "ax[2, 0].plot(history.history['top5_acc'])\n",
        "ax[2, 1].plot(history.history['val_top5_acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkPn1KCd8sy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_val_acc = max(history.history['val_acc']) * 100\n",
        "best_val_top5 = max(history.history['val_top5_acc']) * 100\n",
        "\n",
        "print(f'Best val acc:  {best_val_acc:2.2f}%')\n",
        "print(f'Best val top5: {best_val_top5:2.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpZpgsVl9uDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(image_path, size):\n",
        "    \"\"\"\n",
        "    Load an image as a Numpy array.\n",
        "    :param image_path:  Path of the image\n",
        "    :param size:        Target size\n",
        "    :return             Image array, normalized between 0 and 1\n",
        "    \"\"\"\n",
        "    image = img_to_array(load_img(image_path, target_size=size)) / 255.\n",
        "    return image\n",
        "\n",
        "\n",
        "def process_predictions(class_probabilities, class_readable_labels, k=5):\n",
        "    \"\"\"\n",
        "    Process a batch of predictions from our estimator.\n",
        "    :param class_probabilities:     Prediction results returned by the Keras \n",
        "                                    classifier for a batch of data\n",
        "    :param class_readable_labels:   List of readable-class labels, for display\n",
        "    :param k:                       Number of top predictions to consider\n",
        "    :return                         Readable labels and probabilities for the \n",
        "                                    predicted classes\n",
        "    \"\"\"\n",
        "    topk_labels, topk_probabilities = [], []\n",
        "    for i in range(len(class_probabilities)):\n",
        "        # Getting the top-k predictions:\n",
        "        topk_classes = sorted(np.argpartition(class_probabilities[i], -k)[-k:])\n",
        "    \n",
        "        # Getting the corresponding labels and probabilities:\n",
        "        topk_labels.append([class_readable_labels[predicted] \n",
        "                            for predicted in topk_classes])\n",
        "        topk_probabilities.append(class_probabilities[i][topk_classes])\n",
        "    \n",
        "    return topk_labels, topk_probabilities\n",
        "\n",
        "\n",
        "def display_predictions(images, topk_labels, topk_probabilities):\n",
        "    \"\"\"\n",
        "    Plot a batch of predictions.\n",
        "    :param images:                  Batch of input images\n",
        "    :param topk_labels:             String labels of predicted classes\n",
        "    :param topk_probabilities:      Probabilities for each class\n",
        "    \"\"\"\n",
        "    num_images = len(images)\n",
        "    num_images_sqrt = np.sqrt(num_images)\n",
        "    plot_cols = plot_rows = int(np.ceil(num_images_sqrt))\n",
        "    \n",
        "    figure = plt.figure(figsize=(13,10))\n",
        "    grid_spec = gridspec.GridSpec(plot_cols, plot_rows)\n",
        "    \n",
        "    for i in range(num_images):\n",
        "        img, pred_labels, pred_proba = images[i], topk_labels[i], topk_probabilities[i]\n",
        "        # Shortening the labels to better fit in the plot:\n",
        "        pred_labels = [label.split(',')[0][:20] for label in pred_labels]\n",
        "        \n",
        "        grid_spec_i = gridspec.GridSpecFromSubplotSpec(3, 1, \n",
        "                                                       subplot_spec=grid_spec[i], \n",
        "                                                       hspace=0.1)\n",
        "        \n",
        "        # Drawing the input image:\n",
        "        ax_img = figure.add_subplot(grid_spec_i[:2])\n",
        "        ax_img.axis('off')\n",
        "        ax_img.imshow(img)\n",
        "        ax_img.autoscale(tight=True)\n",
        "        \n",
        "        # Plotting a bar chart for the predictions:\n",
        "        ax_pred = figure.add_subplot(grid_spec_i[2])\n",
        "        ax_pred.spines['top'].set_visible(False)\n",
        "        ax_pred.spines['right'].set_visible(False)\n",
        "        ax_pred.spines['bottom'].set_visible(False)\n",
        "        ax_pred.spines['left'].set_visible(False)\n",
        "        y_pos = np.arange(len(pred_labels))\n",
        "        ax_pred.barh(y_pos, pred_proba, align='center')\n",
        "        ax_pred.set_yticks(y_pos)\n",
        "        ax_pred.set_yticklabels(pred_labels)\n",
        "        ax_pred.invert_yaxis()\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2UxbVn-_uKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_filenames = glob.glob(os.path.join('res', '*'))\n",
        "test_images = np.asarray([load_image(file, size=input_shape[:2]) \n",
        "                         for file in test_filenames])\n",
        "print(f'Test Images: {test_images.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9dmAXpo_-hM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch = test_images[:16]\n",
        "\n",
        "# Our model was trained on CIFAR images, which originally are 32x32px. \n",
        "# We scaled them up to 224x224px to train our model on, but this means \n",
        "# the resulting images had important artifacts/low quality.\n",
        "# To test on images of the same quality, we first resize them to 32x32px,\n",
        "# then to the expected input size (i.e., 224x224px):\n",
        "cifar_original_image_size = cifar_builder.info.features['image'].shape[:2]\n",
        "image_batch_low_quality = tf.image.resize(image_batch, cifar_original_image_size)\n",
        "image_batch_low_quality = tf.image.resize(image_batch_low_quality, input_shape[:2])\n",
        "    \n",
        "\n",
        "predictions = resnet50.predict_on_batch(image_batch_low_quality)\n",
        "print(f'Predicted class probabilities: {predictions.shape}')\n",
        "\n",
        "class_readable_labels = cifar_builder.info.features[\"label\"].names\n",
        "top5_labels, top5_probabilities = process_predictions(predictions, \n",
        "                                                      class_readable_labels)\n",
        "    \n",
        "display_predictions(image_batch, top5_labels, top5_probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}